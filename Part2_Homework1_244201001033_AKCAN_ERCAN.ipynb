{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-09T19:59:53.299715Z",
     "start_time": "2024-04-09T19:59:52.779811Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find Model And Input Image Homography Matrice"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "390350ae33dcf6ca"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# We found corners in section Part1; so, I don't have to find again.\n",
    "model_joined_topbot = [[5, 3], [695, 3]] + [[5, 379], [695, 379]]\n",
    "model_img = cv.imread('images/0.jpg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T19:59:53.304346Z",
     "start_time": "2024-04-09T19:59:53.300667Z"
    }
   },
   "id": "ecad586075a3394",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 588.         -477.17307692], [-53548. -12114.], [-25988.  -4045.], [43417.  6145.], [-3309.6  -510. ], [265.     368.8125], [-1984.6  -203.5], [-5666.25  -938.5 ], [-2667.42857143  -337.5       ], [-23392.  -4055.], [555.94444444 385.83333333], [565.52173913 133.69565217], [-34.92307692 426.92307692], [ 67.51282051 272.84615385], [199.52631579  87.31578947], [-26316.  -5820.], [ 889.5 -932.5], [-1149.  -145.], [-3693.4  -563.6], [-2364.08333333  -273.25      ], [-4147.5  -510.5], [-2946.16666667  -408.83333333], [ 1279. -1468.], [367.61904762 112.42857143], [548.5 600. ], \n",
      "D/E:  2.27086062791827\n",
      "Points on top: [array([199.52631579,  87.31578947]), array([565.52173913, 133.69565217])]\n",
      "Points on bot: [array([ 67.51282051, 272.84615385]), array([555.94444444, 385.83333333])]\n",
      "Mask:\n",
      " [[ 2.61280309e+00  1.87087799e+00 -6.78266530e+02]\n",
      " [-4.03975065e-01  3.20257258e+00 -1.95183303e+02]\n",
      " [ 2.96542741e-04  2.56037551e-03  1.00000000e+00]]\n",
      "Clusters:  6\n"
     ]
    }
   ],
   "source": [
    "image_file = './images/1_man.jpg'\n",
    "default_width = 700\n",
    "frame_raw = cv.imread(image_file)\n",
    "\n",
    "if frame_raw.shape[1] > default_width:\n",
    "    frame_raw = image_resizer(image_file, default_width)\n",
    "    cv.imwrite(\"./output-part2/resized-image.jpg\", frame_raw)\n",
    "\n",
    "cv.imwrite(\"./output-part2/input-gray.jpg\", cv.cvtColor(frame_raw, cv.COLOR_BGR2GRAY))\n",
    "\n",
    "src = frame_raw\n",
    "dst = cv.Canny(src, 50, 200, None, 3)\n",
    "cdst = cv.cvtColor(dst, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "cv.imwrite(\"./output-part2/input-canny.jpg\", dst)\n",
    "\n",
    "\n",
    "frame_lines = dst\n",
    "cartesian_lines = []\n",
    "lines = cv.HoughLines(dst, 1, np.pi / 180, 110, None, 0, 0)\n",
    "\n",
    "#Draw hough Lines\n",
    "\n",
    "if lines is not None:\n",
    "    for i in range(0, len(lines)):\n",
    "        rho = lines[i][0][0]\n",
    "        theta = lines[i][0][1]\n",
    "        a = math.cos(theta)\n",
    "        b = math.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        pt1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
    "        pt2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "        cv.line(cdst, pt1, pt2, (0,0,255), 3, cv.LINE_AA)\n",
    "        \n",
    "cv.imwrite(\"./output-part2/input-image-hough-lines.jpg\", cdst)\n",
    "\n",
    "if lines is not None:\n",
    "    for i in range(0, len(lines)):\n",
    "        pt1, pt2 = add_line(lines, i, frame_lines)\n",
    "        cartesian_lines.append([[pt1[0], pt1[1]], [pt2[0], pt2[1]]])\n",
    "\n",
    "junction_points = junctions(cartesian_lines)\n",
    "junction_points_normalized = []\n",
    "\n",
    "for junction_point in junction_points:\n",
    "    if (junction_point[0] > 0 and junction_point[1] > 0):\n",
    "        if (junction_point[0] < src.shape[1] and junction_point[1] > src.shape[0]):\n",
    "            junction_points_normalized.append(junction_point)\n",
    "\n",
    "cluster_centers = kmeans_centers(junction_points, 25)\n",
    "mark_all(junction_points, frame_lines, rbg=(0, 0, 255))\n",
    "\n",
    "printed = ''\n",
    "for cluster_center in cluster_centers:\n",
    "    printed += str(cluster_center) + ', '\n",
    "\n",
    "print(printed)\n",
    "\n",
    "warped_img = []\n",
    "warped_org_image = []\n",
    "n_noninf = get_noninf(cluster_centers)\n",
    "if (len(n_noninf) >= 4):\n",
    "    top, bot = get_frame_corners(n_noninf)\n",
    "    frame_joined_topbot = top + bot\n",
    "    if (len(frame_joined_topbot) == 4):\n",
    "        # Calculate the mask for the warping\n",
    "        mask, status = cv.findHomography(np.array(frame_joined_topbot), np.array(model_joined_topbot))\n",
    "        print(\"Mask:\\n\", mask)\n",
    "        # Get frame resolution for cv.warpPerspective()\n",
    "        height, width, channels = model_img.shape\n",
    "        warped_img = cv.warpPerspective(frame_raw, mask, (width, height))\n",
    "        \n",
    "        inv_h = np.linalg.inv(mask)\n",
    "        warped_org_image = cv.warpPerspective(warped_img, inv_h, (frame_raw.shape[1], frame_raw.shape[0]), flags=cv.INTER_AREA, borderMode=cv.BORDER_CONSTANT, borderValue=(255, 255, 255))\n",
    "        \n",
    "    mark_all(n_noninf, frame_lines)\n",
    "    print(\"Clusters: \", len(n_noninf))  # Number of cluster centers on screen\n",
    "\n",
    "# cv.imshow(\"Model\", warped_img)\n",
    "cv.imwrite(\"./output-part2/warped_image.jpg\", warped_img)\n",
    "cv.imwrite(\"./output-part2/warped_org_image.jpg\", warped_org_image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T19:59:53.430927Z",
     "start_time": "2024-04-09T19:59:53.305088Z"
    }
   },
   "id": "959a3d8541a4615c",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv.imread('./output-part2/warped_image.jpg')\n",
    "\n",
    "colored_image = np.copy(image)\n",
    "\n",
    "for i in range(image.shape[0]):\n",
    "    for j in range(image.shape[1]):\n",
    "        \n",
    "        pixel_value = image[i, j]\n",
    "        if ((np.mean(pixel_value) > 130 and np.mean(pixel_value) < 200)):\n",
    "            colored_image[i, j] = [0, 0, 0] # Set black\n",
    "\n",
    "cv.imwrite(\"./output-part2/warped-with-colored-image.jpg\", colored_image)\n",
    "\n",
    "# i > 384 - yükseklik\n",
    "# i > 702 - genişlik\n",
    "circle_widths = []\n",
    "\n",
    "for i in range(image.shape[0]):\n",
    "    for j in range(image.shape[1]):\n",
    "        pixel_value = image[i, j]\n",
    "        if (np.mean(pixel_value) < 60):\n",
    "            circle_widths.append(np.mean(pixel_value))\n",
    "            \n",
    "circle_width = np.mean(circle_widths)\n",
    "circle_i = 0\n",
    "circle_j = 0\n",
    "\n",
    "for j in range(image.shape[1]):\n",
    "    player_height = 0\n",
    "    for i in range(image.shape[0]):\n",
    "        pixel_value = image[i, j]\n",
    "        if np.mean(pixel_value) > 46 and np.mean(pixel_value) < 48:\n",
    "            player_height = player_height + 1\n",
    "            if player_height > 50:\n",
    "                circle_i = i\n",
    "                circle_j = j\n",
    "        \n",
    "center_coordinates = (circle_j, circle_i)  \n",
    "radius = round(circle_width)\n",
    "color = (0, 0, 255) \n",
    "thickness = -1\n",
    "colored_image = cv.circle(colored_image, center_coordinates, radius, color, thickness) \n",
    "cv.imwrite(\"./output-part2/colored-image.jpg\", colored_image)\n",
    "\n",
    "final_image = np.copy(image)\n",
    "for i in range(colored_image.shape[0]):\n",
    "    for j in range(colored_image.shape[1]):\n",
    "        pixel_value = colored_image[i, j]\n",
    "        if np.mean(pixel_value) == 0 or pixel_value[2] == 255:\n",
    "            final_image[i,j] = colored_image[i,j]\n",
    "            \n",
    "cv.imwrite(\"./output-part2/final-image.jpg\", final_image)\n",
    "\n",
    "\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:53:22.636994Z",
     "start_time": "2024-04-09T20:53:17.597199Z"
    }
   },
   "id": "41a5cf17503adaaa",
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### I can use this github page\n",
    "\n",
    "https://github.com/mokumus/OpenCV-Homography/tree/master"
   ],
   "id": "ab094f6f7f527cdd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
